export async function getLLMResponse(query: string): Promise<string> {
    // Placeholder untuk memanggil API LLM backend
    // Di sini, Anda bisa menambahkan logika untuk memanggil model LLM seperti LLaMA 3.1

    return `This is a simulated response for the query: "${query}"`;
}
